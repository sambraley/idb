{% extends "base.html" %}
{% block content %}
<div class="container content-container">
	<h1><strong>Table of Contents</strong></h1>
	<div class="row border">
		<div class="col-lg-2">
			<a href="#intro">Introduction</a>
		</div>
		<div class="col-lg-2">
			<a href="#hosting">Hosting</a>
		</div>
		<div class="col-lg-2">
			<a href="#database">Database</a>
		</div>	
		<div class="col-lg-2">
			<a href="#tools">Tools</a>
		</div>	
		<div class="col-lg-2">
			<a href="#api">API</a>
		</div>		
	</div>

	<h1 id="intro"><strong>Introduction</strong></h1>
	<div>
		<h3><strong>Members</strong></h3>
		<p>Nicholas Kantor</p>
		<p>Taben Malik</p>
		<p>Samuel Braley</p>
		<p>Gustavo Osorio</p>
		<p>David Ares</p>
		<p>Scott Farrior</p>
		<h3><strong>About our site</strong></h3>
		<p>The knowledge we have about outer space is always changing and it is very useful for researchers and space enthusiasts to be able to view up to date information of the expansive realm that is outer space. Our goal is to provide is simple way for people to explore the many aspects of objects in space and their relationships to others. Currently this information is held in many different places. This makes it difficult for users to find information about the models we have chosen.</p>
		<h3><strong>How we accomplish our goal</strong></h3>
		<p>We accomplished our goal by going out and scraping data from APIs that provide current information about our models. The names and descriptions of the APIs we used are located at <a href="http://spacecowboys.me/about">http://spacecowboys.me/about</a>. After scraping the data we stored them in json files so that we could read and render their data using python flask.</p>
	</div>
	<h1><strong>Design</strong></h1>
	<div>
		<h3><strong>Space and UML Associations Explained</strong></h3>
		<p>Our models, although for the most part are simple enough to understand on their own, still require a bit of astronomy 101 knowledge to fully grasp our setup. A planet, as defined by Wikipedia, is “an astronomical body orbiting a star or stellar remnant that is massive enough to be rounded by its own gravity, is not massive enough to cause thermonuclear fusion, and has cleared its neighbouring region of planetesimals.” For our purposes, we don’t really need to know the technical parts of what defines a planet, but only the part about it orbiting a star. As a result, planets can have at most one star since they absolutely need something to orbit and it’s typically a star. A planet will also usually be within a galaxy along with satellites and stars. However, there are instances when planets and stars get ejected from their respective galaxy and end up somewhere in between two different galaxies. These are typically referred to as stellar outcasts and rogue planets. This is why we represented these multiplicities as aggregation with an open diamond to galaxy as there can be one or no stars associated with these models. Another aspect of our models worth mentioning is that our satellite model refers to the man made kind. This should not be confused with natural satellites (like earth’s moon) which also orbit planets. Satellite is also the only model that has a many to many relation with stars, planetoids and galaxies. This makes sense because a star and planet can have several satellites in is orbit and of course a galaxy will contain all of those. Our models reflect these concepts: a galaxy is not contained in anything (well, galaxies can be placed in groups, clusters and superclusters, but that’s out of the scope of this project), a star exists in a galaxy and holds the ID of that galaxy, a planet orbits a star and has the ID for that, in addition to existing in a galaxy and holding that ID, and a satellite can orbit a planet and knows the ID of said planet, and it is in effect also orbiting a star and has an ID for that, and finally it is also inside of a galaxy, so the satellite will have an ID of that galaxy.</p>
		<h3><strong>Frontend</strong></h3>
		<p>For our frontend we used bootstrap, css, react, and jquery to make our site look beautiful. Each page consists of a navbar used for navigation between pages and page specific data. For the splash page we implemented a simple carousel to welcome visitors and invite them to explore. The carousel dynamically pulls information from NASA’s picture of the day <a href="https://api.nasa.gov/planetary/apod?api_key=DEMO_KEY">API</a>. For the each of the model pages we created a grid based off of the data in our database. This data is populated through calls to our <a href="http://docs.spacecowboys.apiary.io/">RestAPI</a>. Each element in the grid also links to a page where one can learn more about that specific item. Elements that are associated to other elements, such as a planet that belongs to a galaxy or orbits a star, has a link to that element’s page. We created templates for each model. The data on each page is populated by the model that is passed into the template which was rendered by our backend. The about page displays information about each of the team members, the tools and APIs that are being used, and the statistics about the development of the website. The commits and issues stats are pulled through Github’s develop API. Through react we were able to paginate, sort, and filter our model data. We are able to sort and filter on FILL IN HERE. On the element page for the planet, galaxy, and star models we utilize aladin lite to display an interactive image currently pointed at the coordinates for that celestial object.</p>
		<h3><strong>Backend</strong></h3>
		<p>Our backend uses python Flask to render dynamic templates.  These templates take in a dictionary with the keys matching the attributes of the model. The models are represented by classes using Flask-SQLAlchemy and are designed for a PostgreSQL database. We take advantage of the fact that you don’t need to specify a length for strings in PostgreSQL; all of our string columns are of variable length. As for Flask-SQLAlchemy, we take advantage of backreferences so our one-to-many relations automatically create a many-to-one relation in the child object, making all of our relations bidirectional. We also take advantage of auto-incrementing primary keys, and table names which have been auto-generated from our class names. Through the backend we are also able to run the unit tests and coverage results when requested through “/run_tests”. We do this through the python library unittest.</p>
		<h3><strong>Future features</strong></h3>
		<p>In the future we hope to add searching capabilities to our website. As well as the ability to change the units for data presented about our models. For instance mass could be represented in kilograms or pounds. Distance could be represented in miles or kilometers.</p>
	</div>
	<h1 id="hosting"><strong>Hosting</strong></h1>
	<div>
		<p>We elected to use the <a href="https://cloud.google.com/">Google Cloud Platform’s</a> app engine as our host for our site. This allows us to do our development in a Docker-esque environment with easy version control/deployment, git integration, and DNS management. There is one big downside, however, and that is you will need <strong>patience</strong>. It can take between five and ten minutes to deploy a new version (or to tell if your deployment failed) and trying to do things while GCP is processing something is a good way to get poorly-defined error messages.</p>
		<h3><strong>Initial Setup</strong></h3>
		<p>Make sure not to use an @utexas.edu account as you won’t have the permissions required to create projects under that organization. Register a new account and give everyone in the team access to it. If you have a coupon for GCP, you can use it on that account -- you don’t have to use the coupon on the account it was given to. To use the app engine, you will want to set up a “Hello World” page in the flexible environment, following  <a href="https://cloud.google.com/appengine/docs/flexible/python/quickstart">this tutorial</a>. This will initialize the application engine, setting up whatever google needs to have running under the hood for your app to run.</p>
		<h3><strong>Setting up DNS</strong></h3>
		<p>Now that you have a hello world web app up and running, you might as well link the DNS. Register a domain using <a href="https://www.namecheap.com/">https://www.namecheap.com/</a> (.me domains are free – ours is <a href="http://www.spacecowboys.me/">spacecowboys.me</a>). You’ll then want to set it as a custom domain using <a href="https://cloud.google.com/appengine/docs/standard/python/console/using-custom-domains-and-ssl">this tutorial</a>. You can stop once you reach the end of the “adding a custom domain for your application” section. Following this, you need to set things up on the namecheap side. You’ll want to navigate to <a href="https://ap.www.namecheap.com/">the management page</a> &gt; manage &gt; advanced DNS. Here is where you’ll want to create then entries stated in the google tutorial, using the host of “@” for all but the cname record, which has a host named “www”.</p>
 		<h3><strong>Connecting to GitHub</strong></h3>
		GCP can connect to a few source control platforms, and the one we used was GitHub. To link your repository, go to the main menu (upper-left-hand corner) &gt; Development &gt; Repositories &gt; Create Repository. You’ll need to be the administrator of the GitHub repo you want to link, not just a collaborator. After your repository is linked, you can use it in the app engine by opening the google cloud shell, which is the button in the upper-right-hand corner that looks like a command prompt (alternatively you can use the google cloud sdk, which is not browser based) and issuing the command: <code>gcloud source repos clone &lt;repo name&gt;</code> <strong>NOTE:</strong> Even though your repository might be automatically mirrored to the google cloud source control, it is NOT automatically mirrored to the shell. You will still need to use git pull to fast-forward before deploying an app.
		<h3><strong>Deploying an App</strong></h3>
		<p>You need two main files to deploy an app: app.yaml and requirements.txt. They should both be located at the root directory of your application (where your program entry point is). The app.yaml tells the app engine what runtime you’re using, if you’re using the standard or flexible environment, your program entry point, and many other possible options, <a href="https://cloud.google.com/appengine/docs/standard/python/config/appref">located here</a>. Our app.yaml is as follows:</p>
		<code>runtime: python</code>
 		<br>
		<code>env: flex</code>
 		<br>
		<code>entrypoint: gunicorn -b :$PORT idb:app</code>
 		<br>
		<code>runtime_config:</code>
 		<br>
  	<code>python_version: 3</code>
 		<br>
		<p>Which is pretty much the standard yaml found <a href="https://cloud.google.com/appengine/docs/flexible/python/configuring-your-app-with-app-yaml">here</a>, but it has two notable changes. The first is relatively small, for the entrypoint we changed “main” to the name of our application -- idb. The other is a bit more important, and has to do with the app engine’s automatic scaling. By default, GCP will run two instances of your app 24/7. While this does reduce latency for the end user, you are charged by the hour for each instance. You will end up bleeding money if you don’t limit the automatic scaling to a maximum of a single instance when not idle, and zero instances when idle.</p>
 		<br>
 		<p>requirements.txt contains a list of libraries that GCP will automatically install upon deployment using pip. The format used is &lt;package name&gt;==&lt;version&gt; Our requirements.txt is as follows:</p>
		<code>Flask==0.12</code>
 		<br>
		<code>Flask-SQLAlchemy==2.2</code>
 		<br>
		<code>gunicorn==19.7.0</code>
 		<br>
		<p>Once these two files are in place with the rest of your code, you can deploy your app by opening the cloud shell, navigating to the <strong>same directory</strong> as your app.yaml, and issuing the command: <code>gcloud app deploy [-v &lt;version name&gt;]</code> The -v &lt;version name&gt; is optional, but without it the name of your deployment will just be a timestamp. If you specify a name of an existing version, GCP will go ahead and overwrite that version for you.</p>
		<p>After 5-10 minutes, your deployment should be up and running, and you can see it in: Main Menu &gt; App Engine &gt; Versions</p>
 		<p>From this screen you can also do things like stop a version, delete a version, and also migrate traffic. You can click on the version name to pull up the web page that version is currently serving.</p>
		<p>Which version users are sent to when they navigate to your domain name depends on your traffic allocation. You can split traffic among multiple versions, but for this project, that is not particularly useful. What may be useful is to migrate traffic from one version to another. To do this, click the checkbox next to the version you want to receive traffic, and click the migrate traffic button.</p>
		<h3><strong>Setting up HTTPS</strong></h3>
		<p>Through Namecheap we were able to create a free SSL certificate that is verified through Comodo. This will encrypt all access to our site and creates a safe browsing environment for our users. In order for SSL certificates to work, the ownership of the domain name has to be proved. This was done through email confirmation. After that a certificate and RSA private key was issued out to the domain owner email. We then uploaded the certificate and RSA private key into out GCP app engine settings.</p>
	</div>
	<h1 id="database"><strong>Database</strong></h1>
	<div>
		<h3><strong>Setting up</strong></h3>
		<p>We decided to use Google Cloud Platform’s storage system for SQL. To set it up we had to specify the type (PostgreSQL) and choose how much space and processing power we would allocate to the storage space. We then had to set up authentication. Since we didn’t want users of our website to be able to write to our database, we created two accounts. One with administrator access and one with read only access. For all queries to the database using our API calls the read only access authentication is used.</p>
		<h3><strong>Storing data</strong></h3>
		<p>For the most part we just used the parsed json files from the previous phase to populate the database. The only major difference was that we switched to aladin lite for images, so we had to re-scrap our image data in order to store it in a database.</p>
		<h3><strong>Querying data</strong></h3>
		<p>We utilized flask-restless which automatically queried the database on API calls based off of our models. This implementation seemed to be the easiest route especially because of the thorough documentation of flask-restless is very thorough. </p>
	</div>
	<h1 id="tools"><strong>Tools</strong></h1>
	<div>
		<h3><strong>Frontend Tools</strong></h3>
		<p>In order to make our website have visual appeal as well as quick responses to user interaction we had to utilize a few tools designed for frontend development.</p>
		<h5><strong>React</strong></h5>
		<p>React is a javascript framework developed by Facebook used to develop with a more object oriented design. Within React we utilized ES6 and JSX which gave us more JavaScript features and syntax. We primarily used React to paginate, sort, and filter our models, but we also used it for the carousel, navbar, and about page.</p>
		<h5><strong>Babelify and Browserify</strong></h5>
		<p>We used babelify to compile our ES6 React files into ES5 JavaScript. This was then passed to Browserify which compiled the ES5 JavaScript into vanilla browser readable code. We run the compilation script every time a change is made in our React files. We considered using automated compilers like webpack or gulp, but in the end decided to that those tools were an unnecessary feature for our project.</p>
		<h5><strong>Bootstrap</strong></h5>
		<p>Bootstrap and css were used for styling and elements of our website. The bootstrap libraries are well documented and used in practice everywhere.</p>
		
		<h3><strong>Backend Tools</strong></h3>
		<p>In order to have responsive backend, we use a flask suite of packages to serve our pages and run our API endpoints.</p>
		<h5><strong>Flask</strong></h5>
		<p>The base of Flask is a microframework for python based on Jinja2. Flask is an easy way to create a website right out of the box. The developers of Flask have also created many attachments that integrate Flask with many common aspects of websites, such as Restful APIs and databases. </p>
		<h5><strong>Flask-Restless</strong></h5>
		<p>Flask-Restless is an amazing python package that integrates with Flask and SQLAlchemy and automatically sets up the endpoints for a Restful API. Flask restless utilizes the models that you define for your database to create an API. It sets up a url endpoint such as “&lt;base-url&rt;/&lt;api-prefix&rt;/&lt;model-name&rt;/&lt;unique-identifier&rt;”. Restless also automatically sets up the ability to have search queries and filter queries. Out of all of the tools we have used in this project, Flask-Restless has been the easiest to use and the most useful tool in our development stack. The only downside is that the package is relatively new. Version 0.17 is stable, however there are some features that don’t exist just yet. While Restless automatically sets up everything for us, there are somethings that Restless does that we cannot eliminate or control, such as extraneous API endpoints.</p>
		<h5><strong>Flask-SQLAlchemy</strong></h5>
		<p>Flask-SQLAlchemy is an extension for Flask that adds support for the object relational mapper SQLAlchemy. The extension is relatively new but integrates well with flask and simplifies using SQLAlchemy. The main differences from regular SQLALchemy is that it gives you a scoped session to work with along with useful creatAll() and dropAll() functions that will create the necessary tables. Another difference is that any session that is not committed will automatically get removed by Flask-SQLAlchemy at the end of the request.</p>

		<h3><strong>Data Sources</strong></h3>
		<p>Data used on our website comes from several different APIs and databases. Each source is for a particular set of elements. The amount of different sources shows why we are creating this site. As mentioned in our goal, we strive to have a simple way to access astronomical information. Unfortunately, the APIs that exist for astronomical data are old and complex. Here are the APIs we use and the data we use from them:</p>
		<h5><strong>Exoplanet Archive</strong></h5>
		<p>The Exoplanet Archive is an extensive database of exoplanets and objects of interest discovered by the Kepler Space Telescope. The database is hosted by Caltech and is open to the public. Therefore, an API key or account is not required for the exoplanet archive. The archive is our source for exoplanets and stars that the exoplanets orbit.</p>
		<h5><strong>SIMBAD</strong></h5>
		<p>SIMBAD is an astronomical database containing information from several sources of satellites and research. SIMBAD has a restful API that allows users to search for astrophysical elements in the database. No API key or account is required to pull the information. For our project, SIMBAD is used to gather information on galaxies and stars. Despite it being a RESTful architecture, SIMBAD is rather old and doesn’t return json data. All data requested comes in plain ascii form. This requires some extra file manipulation in order to collect the data.</p>
		<h5><strong>Aladin Lite</strong></h5>
		<p>Aladin Lite is a star mapping tool that allows users to find pictures of stars, galaxies, and arbitrary locations. This service is used in our website as the main source of pictures for stars and galaxies. While the javascript package is extremely useful, Aladin lite did not work well with React. Aladin Lite can only be embedded in a straight html page. We were able to change our pages to allow Aladin Lite in a single instance page, however making a view of multiple instances, such as the grid view of our galaxies, was not possible with Aladin.</p>
		<br/>
		<p>The solution to this was creating a script that uses Aladin lite to download a base64 encoded string URI that represents the picture. The script could be made to download a single picture but any attempt to programmatically get all of the images blows up the browsers used to download them. The script then was used to efficiently get a single picture of a given object. And then we have to run that script manually for every object. Considering how many stars, galaxies, and planets we could potentially have in the database, it would be beneficial to find a better way to programmatically collect these pictures. Or the better solution would be to integrate Aladin Lite in all places.</p>
		<h5><strong>SDSS SkyServer</strong></h5>
		<p>The SDSS SkyServer is a database containing the collection of star maps and astrophysical information from the Sloan Digital Sky Survey mission. SkyServer is also a public database and API with no account required. Due to its limited data set, SkyServer is only a secondary source for photos and star information. SDSS actually has a good solution to our image problem. Their API has an endpoint that generates a URL of an image. However, since the SDSS only covered a portion of the sky, not all of our planets, stars, and galaxies can be found on the SDSS SkyServer.</p>
		<h5><strong>Launch Library</strong></h5>
		<p>Launch Library is an API dedicated to pulling information on rocket launches. The API is public and no account is needed to access the information. While their main purpose is to supply data on all rocket launches, we use their database to find information on satellites. Again images were tricky to produce for satellites through this API. Launch Library provides a wikiURL attribute that links to more information about the satellite. Using MediaWikiAPI we can search for wiki photos and grab the first photo that appears in the search. At first this seemed to work great. Eventually we realized that, while the URLs were from the wiki page of the satellite, they were sometimes not the main picture of the satellite. So this was another chance to manually curate some of the data. Finding a way to programmatically collect images in general seems to be the hardest part of our dataset.</p>
		<h5><strong>NASA apod</strong></h5>
		<p>Apod (Astronomical picture of the day) is an API used to provide new pictures and information on a daily basis. We used their API for our splash page carousel, which automatically updates to the new image of the day. Our carousel uses pictures from the past five days of APOD which adds to a dynamic experience to the website.</p>
		<h5><strong>Github API</strong></h5>
		<p>The Github developer API provides statistics and details about publicly available repositories. We used the API to gather data about the number of commits and issues both overall and per member.</p>
		<h3><strong>Limitations</strong></h3>
		<p>With the provided APIs, there are some limitations to the data we can gather. Unfortunately, there is no database and API that provides information on the planets inside our solar system. Since there are only eight (or nine) instances of planets inside our solar system, it seems impractical to host a dedicated database for just those eight instances. Other databases that have information on planets always focus on exoplanets (planets outside the solar system). Also, any database with information about objects in our solar system focus on elements that have a large quantity such as asteroids and comets. Therefore any information regarding this solar system’s planets have to be hardcoded.</p>
	</div>
	<h1 id="api"><strong>RESTful API</strong></h1>
	<div>
		<p>Our API Apiary page can be found at <a href="http://docs.spacecowboys.apiary.io/#reference">http://docs.spacecowboys.apiary.io/#reference</a>. Each model (galaxies, planetoid bodies, stars, and satellites) have three different types of GET calls.</p>
		<br/>
		<p>The first is a GET by ID, where the PID, or primary ID is a parameter in the query and then the response is either a singular instance of that model with the matching ID in JSON format or a 204 response code, to signify that the request was received but no instance was found.</p>
		<br/>
		<a href="http://spacecowboys.me/api/v1/satellites/1">http://spacecowboys.me/api/v1/satellites/1</a>
		<p>The second is a collective GET that returns a list of models. The optional parameters for this request are results_per_page and page with respective defaults 9 and 1.</p>
		<br/>
		<a href="http://spacecowboys.me/api/v1/satellites?results_per_page=9&page=1">http://spacecowboys.me/api/v1/satellites?results_per_page=9&page=1</a>
		<p>The final GET returns the entire collection of a given model based off of a filter. You are able to filter off of any operation and any attribute of that specific model. You are also able to specify ascending or descending.</p>
		<br/>
		<a href="http://spacecowboys.me/api/v1/satellites?q=%7B%22order_by%22%3A%5B%7B%22field%22%3A%22name%22%2C%22direction%22%3A%22desc%22%7D%5D%2C%22filters%22%3A%5B%7B%22name%22%3A%22name%22%2C%22op%22%3A%22%3D%3D%22%2C%22value%22%3A%22SARAL%22%7D%5D%7D">http://spacecowboys.me/api/v1/satellites?q=%7B%22order_by%22%3A%5B%7B%22field%22%3A%22name%22%2C%22direction%22%3A%22desc%22%7D%5D%2C%22filters%22%3A%5B%7B%22name%22%3A%22name%22%2C%22op%22%3A%22%3D%3D%22%2C%22value%22%3A%22SARAL%22%7D%5D%7D</a>
		<p>We decided to not have any POST or DELETE queries because we don’t want anyone to add or remove stars, galaxies, planetoid bodies, or satellites from our database. A lot of these celestial objects are well documented and we can really only allow trusted sources (like NASA) to supply any data for us. We’d like to avoid letting someone add the whole Star Wars universe to our database.</p>
	</div>
</div>
{% endblock %}
